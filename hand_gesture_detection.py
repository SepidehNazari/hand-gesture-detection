# -*- coding: utf-8 -*-
"""hand-gesture-detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/134wmX50K1aIlVDVgkREhRtQQ7RGQf6YI

# Load data from Google Drive
"""

!pip install --quiet gdown
!gdown --id 1yDktXuw16oRq0v_TwihBTP9KX6mJ4VhX
!unzip -q /content/Diverse_hand_gesture_dataset.zip

class_mapping = {
    0: 'zero',
    1: 'dislike',
    2: 'five',
    3: 'exactly',
    4: 'two',
    5: 'three',
    6: 'left',
    7: 'like' }

train_path = '/content/train'
test_path = '/content/test'

"""# show simple"""

import matplotlib.pyplot as plt
import os

# read text file
c =os.path.join(train_path ,'1479.txt')
txt = open(c).read()
print('txt file : ' ,txt)
print('class_name: ' , class_mapping[int(txt[0])])

# show image
img = plt.imread(os.path.join(train_path , '1479.png'))
print('shape of image: ',img.shape)
plt.imshow(img)
plt.axis('off')

"""# Preprocessing Data"""

import random

imagepath=[]
for filename in os.listdir(train_path):
  ext = filename.endswith('.png')
  if ext :
    imagepath.append(filename)

random.shuffle(imagepath)

!pip install tensorflow

from tensorflow import keras
from tensorflow.keras.preprocessing.image import load_img , img_to_array
import numpy as np


boxes=[]
images=[]
labels=[]

for filename in imagepath :
  text = filename.replace('.png' , '.txt')
  label , startx , starty , endx , endy = open(os.path.join(train_path , text)).read().split(' ')

  img = load_img(os.path.join(train_path , filename) , target_size=(224,224))
  img = img_to_array(img)

  boxes.append([startx , starty , endx , endy])
  images.append(img)
  labels.append(label)

import numpy as np

images = np.array(images, dtype='float32')/255.0
boxes = np.array(boxes, dtype='float32')
labels = np.array(labels, dtype='int32')

"""# Labels one hot"""

labels= keras.utils.to_categorical(labels , num_classes= 8)

"""# Split to train and test"""

from sklearn.model_selection import train_test_split

split = train_test_split(images , boxes , labels , test_size = 0.2 , random_state = 42)

(imagestrain , imagesval, boxestrain , boxesval, labelstrain , labelsval) = split

"""# Creat model"""

from keras.layers import Input
from keras.layers import Dense , Dropout ,  Flatten , GlobalAveragePooling2D
from keras.models import Model
from keras.applications import MobileNetV2

mobilenet = MobileNetV2(weights ='imagenet',include_top=False , input_tensor=Input(shape=(224,224,3)))
mobilenet.trainable = False

gap = GlobalAveragePooling2D()(mobilenet.output)

# boxes
x = Dense(128 , activation = 'relu')(gap)
x = Dense(64 , activation = 'relu')(x)
x = Dense(32 , activation = 'relu')(x)
x = Dense(4 , activation = 'sigmoid' , name = 'box')(x)

# label
y = Dense(512 , activation='relu')(gap)
y = Dropout(0.5)(y)
y = Dense(512 , activation='relu')(y)
y = Dropout(0.5)(y)
y = Dense(8 , activation='softmax' , name = 'class_label')(y)


model = Model(inputs = mobilenet.input , outputs = [x , y])

"""# Compile"""

losses ={ 'box' : 'mse',
          'class_label' : 'categorical_crossentropy'
        }

lossweights = {'box' : 1.0,
              'class_label' : 1.0
              }

metrics = {'box' : None,
           'class_label' : 'accuracy'
          }

opt = keras.optimizers.Adam(learning_rate=1e-4)
model.compile(loss=losses, optimizer=opt, metrics=metrics, loss_weights=lossweights)

"""# Train"""

from keras.callbacks import ModelCheckpoint ,EarlyStopping

callback = ModelCheckpoint('hand_gesture.keras',
                           monitor='val_class_label_accuracy',
                           save_best_only=True ,save_weights_only=False,
                           verbose=1)

traintarget = {
    'box' : boxestrain ,
    'class_label' :labelstrain
              }

valtarget = {
    'box' : boxesval ,
    'class_label' : labelsval
            }

H = model.fit(imagestrain , traintarget ,
              validation_data = (imagesval , valtarget) ,
              batch_size=32 ,
              epochs = 10 ,
              callbacks=[callback])

H = model.fit(imagestrain , traintarget ,
              validation_data = (imagesval , valtarget) ,
              batch_size=32 ,
              epochs = 5 ,
              callbacks=[callback])

"""# Save model"""

from google.colab import drive
drive.mount('/content/drive')

import shutil

colab_path ='/content/hand_gesture.keras'
drive_path="/content/drive/MyDrive/hand_gesture.keras"

shutil.copy(colab_path, drive_path)
print("Model saved to Google Drive:", drive_path)

"""# Plot loss and accuracy"""

name = ['loss' , 'box_loss' , 'class_label_loss']
n = np.arange(0,H.params['epochs'])
plt.style.use('ggplot')
(fig , ax) = plt.subplots(3,1 , figsize=(13,13))
for (i , l) in enumerate(name):
  title = f'loss for {l}' if l != 'loss' else 'total loss'
  ax[i].set_title(title)
  ax[i].set_xlabel('Epoch')
  ax[i].set_ylabel('loss')
  ax[i].plot(n , H.history[l] , label = l)
  ax[i].plot(n , H.history[f'val_{l}'] , label=f'val_{l}')
  ax[i].legend()

plt.tight_layout()

plt.style.use('ggplot')
plt.figure()
plt.plot(n, H.history['class_label_accuracy'] , label= 'class_label_accuracy')
plt.plot(n , H.history['val_class_label_accuracy'] , label= 'val_class_label_accuracy')
plt.title('Class Label Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower left')

"""# Predict"""

def inference(imagePath):
    # load the input image (in Keras format) from disk and preprocess
    # it, scaling the pixel intensities to the range [0, 1]
    image = load_img(imagePath, target_size=(224, 224))
    image = img_to_array(image) / 255.0
    image = np.expand_dims(image, axis=0)
    boxes_pre , label_pre =  model.predict(image)

    class_id = int(np.argmax(label_pre[0]))
    label = class_mapping[class_id]

    img = plt.imread(imagePath)
    image = np.copy(img)
    x, y, w, h = boxes_pre[0]
    H, W = image.shape[:2]
    x, y, w, h = x*W, y*H, w*W, h*H
    x1, y1 = int(x - w/2), int(y - h/2)
    x2, y2 = int(x + w/2), int(y + h/2)

    cv2.rectangle(image, (x1,y1), (x2,y2), (0,255,0), 2)
    cv2.putText(image, label, (x1, max(0,y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0,255,0), 2)
    plt.imshow(image)
    plt.axis('off')

path ='/content/test/five/10088.png'
inference(path)